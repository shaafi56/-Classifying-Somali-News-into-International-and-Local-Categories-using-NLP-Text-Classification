{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaafi56/-Classifying-Somali-News-into-International-and-Local-Categories-using-NLP-Text-Classification/blob/main/update%20two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install WordCloud\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "qUqFXLaOM5un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources if not already downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "oC3an9kDNA6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "# Assuming the uploaded file is named 'example.docx'\n",
        "doc = Document('datasets.docx')\n",
        "\n",
        "# Extract text from each paragraph in the document\n",
        "text = []\n",
        "for paragraph in doc.paragraphs:\n",
        "    text.append(paragraph.text)\n",
        "\n",
        "# Print the extracted text\n",
        "for line in text:\n",
        "    print(line)\n"
      ],
      "metadata": {
        "id": "X8opcqlrS0Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(text))\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.title('Word Cloud for News Text')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "DriEFBxcTaHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = pd.DataFrame({'Text': text}) # Create a DataFrame from the list of text\n",
        "text_df['Tokenized_Text'] = text_df['Text'].apply(lambda x: word_tokenize(x)) # Tokenize the text in the DataFrame"
      ],
      "metadata": {
        "id": "i71116iWV_5f"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopword Removal\n",
        "#stop_words = ['waa', 'waana', 'waan', 'ah', 'oo', 'ee', 'waxey', 'ugu', 'waxa','eey', 'iyo', 'aad', 'baan', 'u', 'leh', 'beey', 'ahna', 'tiq', 'sidoo', 'kalena', 'laakiin','ay','is','ayaa', 'isku', 'ka',  'ku', 'lagu', 'ayay',  'ayuu', 'inuu', 'inaa', 'si', 'laga', 'in', 'haya', 'haaya', 'intii', 'uu', 'ii', 'la', 'looga', 'Mar', 'kaliya', 'waxaa', 'loo']\n",
        "stop_words = ['waa', 'waana', 'waan', 'ah', 'oo', 'ee', 'waxey', 'ugu', 'waxa',\n",
        "             'eey', 'iyo', 'aad', 'baan', 'u', 'leh', 'yar', 'yaraaday', 'yarayd', 'yeesheen', 'yeeshee', 'beey', 'ahna', 'tiq', 'oo', 'yimid', 'yiri' 'Ku','ee' 'sidoo', 'kalena', 'laakiin',\n",
        "             'yeeshay','yesheen', 'yaala', 'ay', 'yaabaa', 'yaabo', 'is', 'yare', 'yaab', 'yeesho', 'yareeyo','yeelatay','ayaa','isku', 'ka', 'ku', 'yiri','yimaadaan','yimaaday','yimaaday','yihiin', 'lagu', 'ayay',  'ayuu',\n",
        "              'inuu', 'inaa', 'si', 'laga', 'in', 'yaryar','yaalla', 'yaal','yaalay', 'haya', 'haaya', 'intii', 'uu', 'ii', 'la', 'looga','mar','kaliya','loo','yahay','sida','soo']\n",
        "text_df['Filtered_Text'] = text_df['Tokenized_Text'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
        "stopWords = list(stop_words)"
      ],
      "metadata": {
        "id": "c_PoektYM6Xi",
        "outputId": "d975600f-4af3-4c3e-be79-2933f71fbc00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['waa', 'waana', 'waan', 'ah', 'oo', 'ee', 'waxey', 'ugu', 'waxa', 'eey', 'iyo', 'aad', 'baan', 'u', 'leh', 'yar', 'yaraaday', 'yarayd', 'yeesheen', 'yeeshee', 'beey', 'ahna', 'tiq', 'oo', 'yimid', 'yiriKu', 'eesidoo', 'kalena', 'laakiin', 'yeeshay', 'yesheen', 'yaala', 'ay', 'yaabaa', 'yaabo', 'is', 'yare', 'yaab', 'yeesho', 'yareeyo', 'yeelatay', 'ayaa', 'isku', 'ka', 'ku', 'yiri', 'yimaadaan', 'yimaaday', 'yimaaday', 'yihiin', 'lagu', 'ayay', 'ayuu', 'inuu', 'inaa', 'si', 'laga', 'in', 'yaryar', 'yaalla', 'yaal', 'yaalay', 'haya', 'haaya', 'intii', 'uu', 'ii', 'la', 'looga', 'mar', 'kaliya', 'loo', 'yahay', 'sida', 'soo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "MZe_NSFjZr3L"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = nlp(text_df['Text'].str.cat(sep=' '))\n",
        "print(docs)"
      ],
      "metadata": {
        "id": "6ZXB083aZ7s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h7rrT-OBdsbz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}